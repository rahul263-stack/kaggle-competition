{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.2.1-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rahul\\miniconda3\\envs\\ml\\lib\\site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\rahul\\miniconda3\\envs\\ml\\lib\\site-packages (from lightgbm) (1.7.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\rahul\\miniconda3\\envs\\ml\\lib\\site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\rahul\\miniconda3\\envs\\ml\\lib\\site-packages (from lightgbm) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahul\\miniconda3\\envs\\ml\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rahul\\miniconda3\\envs\\ml\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-07T12:59:01.533008Z",
     "iopub.status.busy": "2021-09-07T12:59:01.532626Z",
     "iopub.status.idle": "2021-09-07T12:59:43.142762Z",
     "shell.execute_reply": "2021-09-07T12:59:43.141889Z",
     "shell.execute_reply.started": "2021-09-07T12:59:01.53293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly as py\n",
    "from statistics import mean\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected = True)\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#########################################################\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "ss = pd.read_csv('sample_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T12:59:43.144465Z",
     "iopub.status.busy": "2021-09-07T12:59:43.14413Z",
     "iopub.status.idle": "2021-09-07T12:59:43.248481Z",
     "shell.execute_reply": "2021-09-07T12:59:43.247729Z",
     "shell.execute_reply.started": "2021-09-07T12:59:43.144431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f65</th>\n",
       "      <th>f66</th>\n",
       "      <th>f67</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71</th>\n",
       "      <th>f72</th>\n",
       "      <th>f73</th>\n",
       "      <th>f74</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76</th>\n",
       "      <th>f77</th>\n",
       "      <th>f78</th>\n",
       "      <th>f79</th>\n",
       "      <th>f80</th>\n",
       "      <th>f81</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>f84</th>\n",
       "      <th>f85</th>\n",
       "      <th>f86</th>\n",
       "      <th>f87</th>\n",
       "      <th>f88</th>\n",
       "      <th>f89</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>f101</th>\n",
       "      <th>f102</th>\n",
       "      <th>f103</th>\n",
       "      <th>f104</th>\n",
       "      <th>f105</th>\n",
       "      <th>f106</th>\n",
       "      <th>f107</th>\n",
       "      <th>f108</th>\n",
       "      <th>f109</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10859</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>-37.566</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.28915</td>\n",
       "      <td>-10.25100</td>\n",
       "      <td>135.12</td>\n",
       "      <td>168900.0</td>\n",
       "      <td>3.992400e+14</td>\n",
       "      <td>86.489</td>\n",
       "      <td>0.59881</td>\n",
       "      <td>1.423200e+09</td>\n",
       "      <td>0.27240</td>\n",
       "      <td>9.455600</td>\n",
       "      <td>-0.050305</td>\n",
       "      <td>1938.300</td>\n",
       "      <td>8.6331</td>\n",
       "      <td>4.0607</td>\n",
       "      <td>26.8670</td>\n",
       "      <td>-1.180</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>1.5397</td>\n",
       "      <td>135.3200</td>\n",
       "      <td>-1.4965</td>\n",
       "      <td>440.080</td>\n",
       "      <td>2.590100e+12</td>\n",
       "      <td>2.194200e+09</td>\n",
       "      <td>2968800.0</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>13.3270</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>18509.0</td>\n",
       "      <td>146820.0</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>1.090600e+16</td>\n",
       "      <td>1705.40</td>\n",
       "      <td>414.29</td>\n",
       "      <td>3.5392</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>0.968930</td>\n",
       "      <td>18.3880</td>\n",
       "      <td>-0.001583</td>\n",
       "      <td>7.7059</td>\n",
       "      <td>5.9325</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>4.5604</td>\n",
       "      <td>0.61122</td>\n",
       "      <td>10.7950</td>\n",
       "      <td>0.341930</td>\n",
       "      <td>0.23501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5237.70</td>\n",
       "      <td>1.29610</td>\n",
       "      <td>163.66</td>\n",
       "      <td>0.40378</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>-0.001446</td>\n",
       "      <td>-0.35416</td>\n",
       "      <td>6.6432</td>\n",
       "      <td>0.30534</td>\n",
       "      <td>0.514020</td>\n",
       "      <td>1.907300e+09</td>\n",
       "      <td>29.861</td>\n",
       "      <td>0.96501</td>\n",
       "      <td>1797.2</td>\n",
       "      <td>72.178</td>\n",
       "      <td>108.6200</td>\n",
       "      <td>1.9799</td>\n",
       "      <td>1.2907</td>\n",
       "      <td>0.99519</td>\n",
       "      <td>1.3228</td>\n",
       "      <td>827.340</td>\n",
       "      <td>7.779900e+14</td>\n",
       "      <td>4.129900e+10</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>6.9835</td>\n",
       "      <td>43956.0</td>\n",
       "      <td>1978.2</td>\n",
       "      <td>5.5084</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>6.1244</td>\n",
       "      <td>1.231800e+11</td>\n",
       "      <td>275.920</td>\n",
       "      <td>5308500.0</td>\n",
       "      <td>1704.000</td>\n",
       "      <td>5.022400e+10</td>\n",
       "      <td>53.3980</td>\n",
       "      <td>-2.2012</td>\n",
       "      <td>6871.0</td>\n",
       "      <td>3.8862</td>\n",
       "      <td>-0.00558</td>\n",
       "      <td>5252.100</td>\n",
       "      <td>166.690</td>\n",
       "      <td>1.6074</td>\n",
       "      <td>0.66534</td>\n",
       "      <td>7768.900</td>\n",
       "      <td>0.99662</td>\n",
       "      <td>1.125700e+11</td>\n",
       "      <td>2.2432</td>\n",
       "      <td>0.934160</td>\n",
       "      <td>0.65056</td>\n",
       "      <td>94569.0</td>\n",
       "      <td>21.471</td>\n",
       "      <td>8214.100</td>\n",
       "      <td>0.288010</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>1.412400e+09</td>\n",
       "      <td>0.11093</td>\n",
       "      <td>-12.2280</td>\n",
       "      <td>1.7482</td>\n",
       "      <td>1.90960</td>\n",
       "      <td>-7.1157</td>\n",
       "      <td>4378.80</td>\n",
       "      <td>1.2096</td>\n",
       "      <td>8.613400e+14</td>\n",
       "      <td>140.1</td>\n",
       "      <td>1.01770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.299610</td>\n",
       "      <td>11822.000</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.45970</td>\n",
       "      <td>-0.83733</td>\n",
       "      <td>1721.90</td>\n",
       "      <td>119810.0</td>\n",
       "      <td>3.874100e+15</td>\n",
       "      <td>9953.600</td>\n",
       "      <td>1.20930</td>\n",
       "      <td>3.334100e+09</td>\n",
       "      <td>0.28631</td>\n",
       "      <td>-0.012858</td>\n",
       "      <td>-0.019912</td>\n",
       "      <td>10.284</td>\n",
       "      <td>6.1872</td>\n",
       "      <td>1.0419</td>\n",
       "      <td>4.6404</td>\n",
       "      <td>31.877</td>\n",
       "      <td>123620.0</td>\n",
       "      <td>1.3951</td>\n",
       "      <td>125.8100</td>\n",
       "      <td>1.1989</td>\n",
       "      <td>136.450</td>\n",
       "      <td>9.098100e+09</td>\n",
       "      <td>4.004100e+10</td>\n",
       "      <td>1564000.0</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>3.1074</td>\n",
       "      <td>1.5033</td>\n",
       "      <td>238000.0</td>\n",
       "      <td>21440.0</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>3.079400e+16</td>\n",
       "      <td>229.10</td>\n",
       "      <td>844.82</td>\n",
       "      <td>1.4680</td>\n",
       "      <td>4726.5</td>\n",
       "      <td>0.915380</td>\n",
       "      <td>-1.5321</td>\n",
       "      <td>0.982600</td>\n",
       "      <td>7.1112</td>\n",
       "      <td>2.0797</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>4.2523</td>\n",
       "      <td>0.41871</td>\n",
       "      <td>5.4499</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.38647</td>\n",
       "      <td>7.3082</td>\n",
       "      <td>283.21</td>\n",
       "      <td>-0.92552</td>\n",
       "      <td>140.80</td>\n",
       "      <td>0.24739</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>-0.22629</td>\n",
       "      <td>2.4246</td>\n",
       "      <td>0.77147</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>1.803700e+09</td>\n",
       "      <td>64.604</td>\n",
       "      <td>0.26265</td>\n",
       "      <td>4455.0</td>\n",
       "      <td>78.339</td>\n",
       "      <td>745.5100</td>\n",
       "      <td>2.9069</td>\n",
       "      <td>1.4826</td>\n",
       "      <td>1.00510</td>\n",
       "      <td>1.4974</td>\n",
       "      <td>84.446</td>\n",
       "      <td>3.505600e+15</td>\n",
       "      <td>2.242300e+09</td>\n",
       "      <td>0.896300</td>\n",
       "      <td>4.6749</td>\n",
       "      <td>17713.0</td>\n",
       "      <td>9003.1</td>\n",
       "      <td>-4.3546</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>6.9191</td>\n",
       "      <td>1.832400e+11</td>\n",
       "      <td>9.651</td>\n",
       "      <td>32800.0</td>\n",
       "      <td>1480.600</td>\n",
       "      <td>2.300600e+10</td>\n",
       "      <td>44.0510</td>\n",
       "      <td>205.6900</td>\n",
       "      <td>4295.3</td>\n",
       "      <td>13.3880</td>\n",
       "      <td>0.46843</td>\n",
       "      <td>754.610</td>\n",
       "      <td>83.233</td>\n",
       "      <td>1.1890</td>\n",
       "      <td>29.55000</td>\n",
       "      <td>7343.700</td>\n",
       "      <td>0.99815</td>\n",
       "      <td>4.877700e+13</td>\n",
       "      <td>1.2708</td>\n",
       "      <td>-0.000969</td>\n",
       "      <td>5.29520</td>\n",
       "      <td>6779.0</td>\n",
       "      <td>227.720</td>\n",
       "      <td>34.342</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.143370</td>\n",
       "      <td>0.049276</td>\n",
       "      <td>1.903200e+09</td>\n",
       "      <td>0.97673</td>\n",
       "      <td>-56.7580</td>\n",
       "      <td>4.1684</td>\n",
       "      <td>0.34808</td>\n",
       "      <td>4.1420</td>\n",
       "      <td>913.23</td>\n",
       "      <td>1.2464</td>\n",
       "      <td>7.575100e+15</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.17803</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>907.270</td>\n",
       "      <td>0.272140</td>\n",
       "      <td>0.45948</td>\n",
       "      <td>0.17327</td>\n",
       "      <td>2298.00</td>\n",
       "      <td>360650.0</td>\n",
       "      <td>1.224500e+13</td>\n",
       "      <td>15827.000</td>\n",
       "      <td>0.38164</td>\n",
       "      <td>1.230300e+09</td>\n",
       "      <td>0.25807</td>\n",
       "      <td>2.455600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.873</td>\n",
       "      <td>7.5463</td>\n",
       "      <td>1.9967</td>\n",
       "      <td>1.9526</td>\n",
       "      <td>817.760</td>\n",
       "      <td>-2948.7</td>\n",
       "      <td>2.0054</td>\n",
       "      <td>1.6826</td>\n",
       "      <td>1.1968</td>\n",
       "      <td>74.624</td>\n",
       "      <td>-3.273900e+10</td>\n",
       "      <td>5.718900e+10</td>\n",
       "      <td>11058.0</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>8.0241</td>\n",
       "      <td>1.1318</td>\n",
       "      <td>27940.0</td>\n",
       "      <td>862460.0</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>5.849100e+13</td>\n",
       "      <td>-897.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3561</td>\n",
       "      <td>3063.4</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>16.1060</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>11.4760</td>\n",
       "      <td>5.3430</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>4.1018</td>\n",
       "      <td>-0.88270</td>\n",
       "      <td>8.1228</td>\n",
       "      <td>-0.676690</td>\n",
       "      <td>0.33770</td>\n",
       "      <td>-1.0732</td>\n",
       "      <td>4097.00</td>\n",
       "      <td>13.45800</td>\n",
       "      <td>159.24</td>\n",
       "      <td>0.32230</td>\n",
       "      <td>0.560090</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>-0.16083</td>\n",
       "      <td>3.5753</td>\n",
       "      <td>0.60970</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>5.271300e+08</td>\n",
       "      <td>14.454</td>\n",
       "      <td>0.11549</td>\n",
       "      <td>14605.0</td>\n",
       "      <td>36.992</td>\n",
       "      <td>-9.6391</td>\n",
       "      <td>64.2670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99278</td>\n",
       "      <td>2.5891</td>\n",
       "      <td>430.400</td>\n",
       "      <td>-4.453500e+13</td>\n",
       "      <td>5.144900e+12</td>\n",
       "      <td>0.099591</td>\n",
       "      <td>6.5516</td>\n",
       "      <td>1887.5</td>\n",
       "      <td>43319.0</td>\n",
       "      <td>4.3931</td>\n",
       "      <td>0.260260</td>\n",
       "      <td>6.1052</td>\n",
       "      <td>1.013300e+11</td>\n",
       "      <td>357.270</td>\n",
       "      <td>1476600.0</td>\n",
       "      <td>90.845</td>\n",
       "      <td>1.306200e+09</td>\n",
       "      <td>2.3731</td>\n",
       "      <td>391.3700</td>\n",
       "      <td>2965.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49459</td>\n",
       "      <td>43.524</td>\n",
       "      <td>138.520</td>\n",
       "      <td>1.1079</td>\n",
       "      <td>0.91948</td>\n",
       "      <td>47.915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.510500e+12</td>\n",
       "      <td>3.4663</td>\n",
       "      <td>0.560950</td>\n",
       "      <td>4.13090</td>\n",
       "      <td>95531.0</td>\n",
       "      <td>39.486</td>\n",
       "      <td>-83.148</td>\n",
       "      <td>0.084881</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>1.436500e+07</td>\n",
       "      <td>0.20102</td>\n",
       "      <td>-5.7688</td>\n",
       "      <td>1.2042</td>\n",
       "      <td>0.26290</td>\n",
       "      <td>8.1312</td>\n",
       "      <td>45119.00</td>\n",
       "      <td>1.1764</td>\n",
       "      <td>3.218100e+14</td>\n",
       "      <td>3838.2</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       f1        f2         f3        f4       f5        f6       f7  \\\n",
       "0   0  0.10859  0.004314    -37.566  0.017364  0.28915 -10.25100   135.12   \n",
       "1   1  0.10090  0.299610  11822.000  0.276500  0.45970  -0.83733  1721.90   \n",
       "2   2  0.17803 -0.006980    907.270  0.272140  0.45948   0.17327  2298.00   \n",
       "\n",
       "         f8            f9        f10      f11           f12      f13  \\\n",
       "0  168900.0  3.992400e+14     86.489  0.59881  1.423200e+09  0.27240   \n",
       "1  119810.0  3.874100e+15   9953.600  1.20930  3.334100e+09  0.28631   \n",
       "2  360650.0  1.224500e+13  15827.000  0.38164  1.230300e+09  0.25807   \n",
       "\n",
       "        f14       f15       f16     f17     f18      f19      f20       f21  \\\n",
       "0  9.455600 -0.050305  1938.300  8.6331  4.0607  26.8670   -1.180   10961.0   \n",
       "1 -0.012858 -0.019912    10.284  6.1872  1.0419   4.6404   31.877  123620.0   \n",
       "2  2.455600       NaN    26.873  7.5463  1.9967   1.9526  817.760   -2948.7   \n",
       "\n",
       "      f22       f23     f24      f25           f26           f27        f28  \\\n",
       "0  1.5397  135.3200 -1.4965  440.080  2.590100e+12  2.194200e+09  2968800.0   \n",
       "1  1.3951  125.8100  1.1989  136.450  9.098100e+09  4.004100e+10  1564000.0   \n",
       "2  2.0054    1.6826  1.1968   74.624 -3.273900e+10  5.718900e+10    11058.0   \n",
       "\n",
       "        f29      f30     f31       f32       f33       f34           f35  \\\n",
       "0  0.001431  13.3270  0.7505   18509.0  146820.0 -0.000276  1.090600e+16   \n",
       "1  0.000204   3.1074  1.5033  238000.0   21440.0 -0.001344  3.079400e+16   \n",
       "2 -0.003097   8.0241  1.1318   27940.0  862460.0 -0.002207  5.849100e+13   \n",
       "\n",
       "       f36     f37     f38     f39       f40      f41       f42      f43  \\\n",
       "0  1705.40  414.29  3.5392  1888.0  0.968930  18.3880 -0.001583   7.7059   \n",
       "1   229.10  844.82  1.4680  4726.5  0.915380  -1.5321  0.982600   7.1112   \n",
       "2  -897.84     NaN  1.3561  3063.4  0.086232  16.1060  0.001481  11.4760   \n",
       "\n",
       "      f44       f45     f46      f47      f48       f49      f50     f51  \\\n",
       "0  5.9325  0.025693  4.5604  0.61122  10.7950  0.341930  0.23501     NaN   \n",
       "1  2.0797  0.042321  4.2523  0.41871   5.4499  0.012737  0.38647  7.3082   \n",
       "2  5.3430  0.012162  4.1018 -0.88270   8.1228 -0.676690  0.33770 -1.0732   \n",
       "\n",
       "       f52       f53     f54      f55       f56       f57      f58     f59  \\\n",
       "0  5237.70   1.29610  163.66  0.40378  0.188600 -0.001446 -0.35416  6.6432   \n",
       "1   283.21  -0.92552  140.80  0.24739 -0.001656 -0.000975 -0.22629  2.4246   \n",
       "2  4097.00  13.45800  159.24  0.32230  0.560090  0.000455 -0.16083  3.5753   \n",
       "\n",
       "       f60       f61           f62     f63      f64      f65     f66  \\\n",
       "0  0.30534  0.514020  1.907300e+09  29.861  0.96501   1797.2  72.178   \n",
       "1  0.77147  0.011613  1.803700e+09  64.604  0.26265   4455.0  78.339   \n",
       "2  0.60970  0.028301  5.271300e+08  14.454  0.11549  14605.0  36.992   \n",
       "\n",
       "        f67      f68     f69      f70     f71      f72           f73  \\\n",
       "0  108.6200   1.9799  1.2907  0.99519  1.3228  827.340  7.779900e+14   \n",
       "1  745.5100   2.9069  1.4826  1.00510  1.4974   84.446  3.505600e+15   \n",
       "2   -9.6391  64.2670     NaN  0.99278  2.5891  430.400 -4.453500e+13   \n",
       "\n",
       "            f74       f75     f76      f77      f78     f79       f80     f81  \\\n",
       "0  4.129900e+10  0.006994  6.9835  43956.0   1978.2  5.5084 -0.001081  6.1244   \n",
       "1  2.242300e+09  0.896300  4.6749  17713.0   9003.1 -4.3546  0.254100  6.9191   \n",
       "2  5.144900e+12  0.099591  6.5516   1887.5  43319.0  4.3931  0.260260  6.1052   \n",
       "\n",
       "            f82      f83        f84       f85           f86      f87  \\\n",
       "0  1.231800e+11  275.920  5308500.0  1704.000  5.022400e+10  53.3980   \n",
       "1  1.832400e+11    9.651    32800.0  1480.600  2.300600e+10  44.0510   \n",
       "2  1.013300e+11  357.270  1476600.0    90.845  1.306200e+09   2.3731   \n",
       "\n",
       "        f88     f89      f90      f91       f92      f93     f94       f95  \\\n",
       "0   -2.2012  6871.0   3.8862 -0.00558  5252.100  166.690  1.6074   0.66534   \n",
       "1  205.6900  4295.3  13.3880  0.46843   754.610   83.233  1.1890  29.55000   \n",
       "2  391.3700  2965.3      NaN  0.49459    43.524  138.520  1.1079   0.91948   \n",
       "\n",
       "        f96      f97           f98     f99      f100     f101     f102  \\\n",
       "0  7768.900  0.99662  1.125700e+11  2.2432  0.934160  0.65056  94569.0   \n",
       "1  7343.700  0.99815  4.877700e+13  1.2708 -0.000969  5.29520   6779.0   \n",
       "2    47.915      NaN  1.510500e+12  3.4663  0.560950  4.13090  95531.0   \n",
       "\n",
       "      f103      f104      f105      f106      f107          f108     f109  \\\n",
       "0   21.471  8214.100  0.288010  0.097826  0.001071  1.412400e+09  0.11093   \n",
       "1  227.720    34.342  0.340300  0.143370  0.049276  1.903200e+09  0.97673   \n",
       "2   39.486   -83.148  0.084881  0.032222  0.001668  1.436500e+07  0.20102   \n",
       "\n",
       "      f110    f111     f112    f113      f114    f115          f116    f117  \\\n",
       "0 -12.2280  1.7482  1.90960 -7.1157   4378.80  1.2096  8.613400e+14   140.1   \n",
       "1 -56.7580  4.1684  0.34808  4.1420    913.23  1.2464  7.575100e+15  1861.0   \n",
       "2  -5.7688  1.2042  0.26290  8.1312  45119.00  1.1764  3.218100e+14  3838.2   \n",
       "\n",
       "      f118  claim  \n",
       "0  1.01770      1  \n",
       "1  0.28359      0  \n",
       "2  0.40690      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T12:59:43.251698Z",
     "iopub.status.busy": "2021-09-07T12:59:43.251431Z",
     "iopub.status.idle": "2021-09-07T12:59:43.346933Z",
     "shell.execute_reply": "2021-09-07T12:59:43.346221Z",
     "shell.execute_reply.started": "2021-09-07T12:59:43.251657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f65</th>\n",
       "      <th>f66</th>\n",
       "      <th>f67</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71</th>\n",
       "      <th>f72</th>\n",
       "      <th>f73</th>\n",
       "      <th>f74</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76</th>\n",
       "      <th>f77</th>\n",
       "      <th>f78</th>\n",
       "      <th>f79</th>\n",
       "      <th>f80</th>\n",
       "      <th>f81</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>f84</th>\n",
       "      <th>f85</th>\n",
       "      <th>f86</th>\n",
       "      <th>f87</th>\n",
       "      <th>f88</th>\n",
       "      <th>f89</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>f101</th>\n",
       "      <th>f102</th>\n",
       "      <th>f103</th>\n",
       "      <th>f104</th>\n",
       "      <th>f105</th>\n",
       "      <th>f106</th>\n",
       "      <th>f107</th>\n",
       "      <th>f108</th>\n",
       "      <th>f109</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>957919</td>\n",
       "      <td>0.16585</td>\n",
       "      <td>0.48705</td>\n",
       "      <td>1295.00</td>\n",
       "      <td>0.02310</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.90188</td>\n",
       "      <td>573.29</td>\n",
       "      <td>3743.7</td>\n",
       "      <td>2.705700e+12</td>\n",
       "      <td>6221.00</td>\n",
       "      <td>1.17200</td>\n",
       "      <td>5.175000e+09</td>\n",
       "      <td>0.25831</td>\n",
       "      <td>3.42050</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>1001.600</td>\n",
       "      <td>10.1040</td>\n",
       "      <td>10.5360</td>\n",
       "      <td>19.517</td>\n",
       "      <td>-1.1209</td>\n",
       "      <td>1577.6</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>96.109</td>\n",
       "      <td>1.1535</td>\n",
       "      <td>95.865</td>\n",
       "      <td>2.847100e+12</td>\n",
       "      <td>9.642100e+10</td>\n",
       "      <td>6406000.0</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>6.6353</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>21723.0</td>\n",
       "      <td>67604.0</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>6.046200e+16</td>\n",
       "      <td>203.580</td>\n",
       "      <td>301.790</td>\n",
       "      <td>1.3461</td>\n",
       "      <td>5524.6</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>21.883</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>7.2113</td>\n",
       "      <td>24.8250</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>-1.08710</td>\n",
       "      <td>7.0561</td>\n",
       "      <td>-1.0615</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.856</td>\n",
       "      <td>449.99</td>\n",
       "      <td>-0.36286</td>\n",
       "      <td>160.63</td>\n",
       "      <td>0.24801</td>\n",
       "      <td>0.62300</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.39384</td>\n",
       "      <td>1.9038</td>\n",
       "      <td>0.068588</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>2.506500e+09</td>\n",
       "      <td>48.164</td>\n",
       "      <td>-0.002272</td>\n",
       "      <td>78643.0</td>\n",
       "      <td>112.360</td>\n",
       "      <td>1021.900</td>\n",
       "      <td>11.481</td>\n",
       "      <td>1.1573</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>1.8192</td>\n",
       "      <td>1096.80</td>\n",
       "      <td>3.004100e+14</td>\n",
       "      <td>2.042300e+09</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>4.6312</td>\n",
       "      <td>1683.10</td>\n",
       "      <td>9833.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510410</td>\n",
       "      <td>4.0322</td>\n",
       "      <td>2.477900e+11</td>\n",
       "      <td>69.264</td>\n",
       "      <td>5494800.0</td>\n",
       "      <td>1239.00</td>\n",
       "      <td>5.349300e+08</td>\n",
       "      <td>5.3086</td>\n",
       "      <td>182.59</td>\n",
       "      <td>829.17</td>\n",
       "      <td>5.2319</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>3640.80</td>\n",
       "      <td>112.12</td>\n",
       "      <td>-0.43442</td>\n",
       "      <td>11.16100</td>\n",
       "      <td>3755.7</td>\n",
       "      <td>0.99926</td>\n",
       "      <td>5.338200e+10</td>\n",
       "      <td>1.3867</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>58.7940</td>\n",
       "      <td>75657.0</td>\n",
       "      <td>187.24</td>\n",
       "      <td>1258.90</td>\n",
       "      <td>0.16334</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>795640000.0</td>\n",
       "      <td>0.16253</td>\n",
       "      <td>-22.1890</td>\n",
       "      <td>2.0655</td>\n",
       "      <td>0.43088</td>\n",
       "      <td>-10.7410</td>\n",
       "      <td>81606.0</td>\n",
       "      <td>1.1940</td>\n",
       "      <td>1.980400e+14</td>\n",
       "      <td>2017.1</td>\n",
       "      <td>0.46357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>957920</td>\n",
       "      <td>0.12965</td>\n",
       "      <td>0.37348</td>\n",
       "      <td>1763.00</td>\n",
       "      <td>0.72884</td>\n",
       "      <td>0.33247</td>\n",
       "      <td>-1.26310</td>\n",
       "      <td>875.55</td>\n",
       "      <td>554370.0</td>\n",
       "      <td>5.955700e+14</td>\n",
       "      <td>934.43</td>\n",
       "      <td>1.89790</td>\n",
       "      <td>4.905100e+09</td>\n",
       "      <td>0.28471</td>\n",
       "      <td>2.13870</td>\n",
       "      <td>-0.034328</td>\n",
       "      <td>35.223</td>\n",
       "      <td>6.5873</td>\n",
       "      <td>12.7340</td>\n",
       "      <td>29.590</td>\n",
       "      <td>4.1639</td>\n",
       "      <td>31915.0</td>\n",
       "      <td>3.1158</td>\n",
       "      <td>109.430</td>\n",
       "      <td>-0.8522</td>\n",
       "      <td>991.370</td>\n",
       "      <td>4.700100e+09</td>\n",
       "      <td>1.618200e+12</td>\n",
       "      <td>967810.0</td>\n",
       "      <td>1.02150</td>\n",
       "      <td>2.9617</td>\n",
       "      <td>0.810310</td>\n",
       "      <td>415570.0</td>\n",
       "      <td>384720.0</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>6.712900e+15</td>\n",
       "      <td>228.590</td>\n",
       "      <td>33.952</td>\n",
       "      <td>1.4938</td>\n",
       "      <td>2067.5</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>32.772</td>\n",
       "      <td>0.092283</td>\n",
       "      <td>6.5363</td>\n",
       "      <td>2.0773</td>\n",
       "      <td>0.046237</td>\n",
       "      <td>4.4590</td>\n",
       "      <td>-0.84092</td>\n",
       "      <td>4.4473</td>\n",
       "      <td>-1.0012</td>\n",
       "      <td>0.00375</td>\n",
       "      <td>99.647</td>\n",
       "      <td>8146.80</td>\n",
       "      <td>22.50400</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.43076</td>\n",
       "      <td>0.74301</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.11692</td>\n",
       "      <td>1.6544</td>\n",
       "      <td>0.467440</td>\n",
       "      <td>0.129650</td>\n",
       "      <td>4.442800e+08</td>\n",
       "      <td>38.506</td>\n",
       "      <td>0.396220</td>\n",
       "      <td>74296.0</td>\n",
       "      <td>93.629</td>\n",
       "      <td>-15.691</td>\n",
       "      <td>30.655</td>\n",
       "      <td>1.2311</td>\n",
       "      <td>1.004400</td>\n",
       "      <td>2.2484</td>\n",
       "      <td>780.87</td>\n",
       "      <td>1.213600e+14</td>\n",
       "      <td>3.488200e+11</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>6.9993</td>\n",
       "      <td>2451.60</td>\n",
       "      <td>10483.0</td>\n",
       "      <td>-5.3544</td>\n",
       "      <td>0.067286</td>\n",
       "      <td>5.4044</td>\n",
       "      <td>2.462600e+11</td>\n",
       "      <td>810.300</td>\n",
       "      <td>860670.0</td>\n",
       "      <td>2165.20</td>\n",
       "      <td>2.711500e+08</td>\n",
       "      <td>10.2320</td>\n",
       "      <td>515.41</td>\n",
       "      <td>262.71</td>\n",
       "      <td>5.6357</td>\n",
       "      <td>0.374220</td>\n",
       "      <td>420.16</td>\n",
       "      <td>116.23</td>\n",
       "      <td>1.26980</td>\n",
       "      <td>0.78619</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>1.00070</td>\n",
       "      <td>2.065000e+13</td>\n",
       "      <td>1.2888</td>\n",
       "      <td>0.248850</td>\n",
       "      <td>9.9857</td>\n",
       "      <td>16323.0</td>\n",
       "      <td>244.46</td>\n",
       "      <td>647.58</td>\n",
       "      <td>0.25382</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>112060000.0</td>\n",
       "      <td>0.81528</td>\n",
       "      <td>-1.6342</td>\n",
       "      <td>1.5736</td>\n",
       "      <td>-1.07120</td>\n",
       "      <td>11.8320</td>\n",
       "      <td>90114.0</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.388000e+16</td>\n",
       "      <td>6638.9</td>\n",
       "      <td>0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>957921</td>\n",
       "      <td>0.12019</td>\n",
       "      <td>0.44521</td>\n",
       "      <td>736.26</td>\n",
       "      <td>0.04615</td>\n",
       "      <td>0.29605</td>\n",
       "      <td>0.31665</td>\n",
       "      <td>2659.50</td>\n",
       "      <td>317140.0</td>\n",
       "      <td>3.977800e+14</td>\n",
       "      <td>131.81</td>\n",
       "      <td>-0.48404</td>\n",
       "      <td>3.800000e+06</td>\n",
       "      <td>0.37173</td>\n",
       "      <td>0.40245</td>\n",
       "      <td>0.015119</td>\n",
       "      <td>1991.600</td>\n",
       "      <td>6.0050</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>11.949</td>\n",
       "      <td>888.0700</td>\n",
       "      <td>887.7</td>\n",
       "      <td>3.5237</td>\n",
       "      <td>108.140</td>\n",
       "      <td>-1.6542</td>\n",
       "      <td>528.140</td>\n",
       "      <td>2.463600e+12</td>\n",
       "      <td>9.005900e+09</td>\n",
       "      <td>7259.3</td>\n",
       "      <td>1.00740</td>\n",
       "      <td>2.6123</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>-208010.0</td>\n",
       "      <td>65708.0</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>8.129800e+13</td>\n",
       "      <td>-84.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7556</td>\n",
       "      <td>4729.2</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>861.660</td>\n",
       "      <td>0.902670</td>\n",
       "      <td>9.3934</td>\n",
       "      <td>58.7850</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>5.6645</td>\n",
       "      <td>-0.62747</td>\n",
       "      <td>6.5806</td>\n",
       "      <td>-1.1282</td>\n",
       "      <td>0.38650</td>\n",
       "      <td>56.547</td>\n",
       "      <td>125.36</td>\n",
       "      <td>12.70300</td>\n",
       "      <td>147.38</td>\n",
       "      <td>0.41437</td>\n",
       "      <td>0.51998</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>-0.12065</td>\n",
       "      <td>5.4115</td>\n",
       "      <td>0.772530</td>\n",
       "      <td>0.128850</td>\n",
       "      <td>5.664900e+09</td>\n",
       "      <td>50.894</td>\n",
       "      <td>0.378710</td>\n",
       "      <td>80045.0</td>\n",
       "      <td>65.224</td>\n",
       "      <td>780.210</td>\n",
       "      <td>14.125</td>\n",
       "      <td>1.1657</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>1.0663</td>\n",
       "      <td>432.01</td>\n",
       "      <td>-5.953100e+11</td>\n",
       "      <td>1.383400e+12</td>\n",
       "      <td>-0.006236</td>\n",
       "      <td>5.6052</td>\n",
       "      <td>866.39</td>\n",
       "      <td>1065.2</td>\n",
       "      <td>-1.4805</td>\n",
       "      <td>0.064203</td>\n",
       "      <td>3.0197</td>\n",
       "      <td>1.684400e+11</td>\n",
       "      <td>212.830</td>\n",
       "      <td>7891000.0</td>\n",
       "      <td>277.16</td>\n",
       "      <td>4.047900e+10</td>\n",
       "      <td>1.1170</td>\n",
       "      <td>393.51</td>\n",
       "      <td>8859.10</td>\n",
       "      <td>8.8098</td>\n",
       "      <td>0.405350</td>\n",
       "      <td>393.65</td>\n",
       "      <td>305.14</td>\n",
       "      <td>1.32660</td>\n",
       "      <td>30.85200</td>\n",
       "      <td>2803.7</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>4.722600e+12</td>\n",
       "      <td>1.5003</td>\n",
       "      <td>0.493380</td>\n",
       "      <td>37.0470</td>\n",
       "      <td>139070.0</td>\n",
       "      <td>2464.00</td>\n",
       "      <td>4724.80</td>\n",
       "      <td>0.29916</td>\n",
       "      <td>0.093046</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>65193000.0</td>\n",
       "      <td>0.81831</td>\n",
       "      <td>-32.7800</td>\n",
       "      <td>2.1364</td>\n",
       "      <td>-1.93120</td>\n",
       "      <td>-3.2804</td>\n",
       "      <td>37739.0</td>\n",
       "      <td>1.1548</td>\n",
       "      <td>1.718100e+14</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>0.13797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       f1       f2       f3       f4       f5       f6       f7  \\\n",
       "0  957919  0.16585  0.48705  1295.00  0.02310  0.31900  0.90188   573.29   \n",
       "1  957920  0.12965  0.37348  1763.00  0.72884  0.33247 -1.26310   875.55   \n",
       "2  957921  0.12019  0.44521   736.26  0.04615  0.29605  0.31665  2659.50   \n",
       "\n",
       "         f8            f9      f10      f11           f12      f13      f14  \\\n",
       "0    3743.7  2.705700e+12  6221.00  1.17200  5.175000e+09  0.25831  3.42050   \n",
       "1  554370.0  5.955700e+14   934.43  1.89790  4.905100e+09  0.28471  2.13870   \n",
       "2  317140.0  3.977800e+14   131.81 -0.48404  3.800000e+06  0.37173  0.40245   \n",
       "\n",
       "        f15       f16      f17      f18     f19       f20      f21     f22  \\\n",
       "0  0.044983  1001.600  10.1040  10.5360  19.517   -1.1209   1577.6  2.1847   \n",
       "1 -0.034328    35.223   6.5873  12.7340  29.590    4.1639  31915.0  3.1158   \n",
       "2  0.015119  1991.600   6.0050   0.9919  11.949  888.0700    887.7  3.5237   \n",
       "\n",
       "       f23     f24      f25           f26           f27        f28      f29  \\\n",
       "0   96.109  1.1535   95.865  2.847100e+12  9.642100e+10  6406000.0  0.00299   \n",
       "1  109.430 -0.8522  991.370  4.700100e+09  1.618200e+12   967810.0  1.02150   \n",
       "2  108.140 -1.6542  528.140  2.463600e+12  9.005900e+09     7259.3  1.00740   \n",
       "\n",
       "      f30       f31       f32       f33       f34           f35      f36  \\\n",
       "0  6.6353 -0.015913   21723.0   67604.0 -0.000227  6.046200e+16  203.580   \n",
       "1  2.9617  0.810310  415570.0  384720.0  0.002243  6.712900e+15  228.590   \n",
       "2  2.6123  1.062500 -208010.0   65708.0  0.001391  8.129800e+13  -84.032   \n",
       "\n",
       "       f37     f38     f39       f40      f41       f42     f43      f44  \\\n",
       "0  301.790  1.3461  5524.6 -0.003163   21.883  0.027383  7.2113  24.8250   \n",
       "1   33.952  1.4938  2067.5 -0.002343   32.772  0.092283  6.5363   2.0773   \n",
       "2      NaN  1.7556  4729.2  0.003527  861.660  0.902670  9.3934  58.7850   \n",
       "\n",
       "        f45     f46      f47     f48     f49      f50     f51      f52  \\\n",
       "0 -0.001420  4.8950 -1.08710  7.0561 -1.0615  0.00010   1.856   449.99   \n",
       "1  0.046237  4.4590 -0.84092  4.4473 -1.0012  0.00375  99.647  8146.80   \n",
       "2  0.007244  5.6645 -0.62747  6.5806 -1.1282  0.38650  56.547   125.36   \n",
       "\n",
       "        f53     f54      f55      f56       f57      f58     f59       f60  \\\n",
       "0  -0.36286  160.63  0.24801  0.62300  0.000116 -0.39384  1.9038  0.068588   \n",
       "1  22.50400  153.40  0.43076  0.74301 -0.000047 -0.11692  1.6544  0.467440   \n",
       "2  12.70300  147.38  0.41437  0.51998  0.000857 -0.12065  5.4115  0.772530   \n",
       "\n",
       "        f61           f62     f63       f64      f65      f66       f67  \\\n",
       "0  0.020439  2.506500e+09  48.164 -0.002272  78643.0  112.360  1021.900   \n",
       "1  0.129650  4.442800e+08  38.506  0.396220  74296.0   93.629   -15.691   \n",
       "2  0.128850  5.664900e+09  50.894  0.378710  80045.0   65.224   780.210   \n",
       "\n",
       "      f68     f69       f70     f71      f72           f73           f74  \\\n",
       "0  11.481  1.1573  0.002995  1.8192  1096.80  3.004100e+14  2.042300e+09   \n",
       "1  30.655  1.2311  1.004400  2.2484   780.87  1.213600e+14  3.488200e+11   \n",
       "2  14.125  1.1657 -0.001285  1.0663   432.01 -5.953100e+11  1.383400e+12   \n",
       "\n",
       "        f75     f76      f77      f78     f79       f80     f81           f82  \\\n",
       "0  0.085500  4.6312  1683.10   9833.6     NaN  0.510410  4.0322  2.477900e+11   \n",
       "1 -0.000792  6.9993  2451.60  10483.0 -5.3544  0.067286  5.4044  2.462600e+11   \n",
       "2 -0.006236  5.6052   866.39   1065.2 -1.4805  0.064203  3.0197  1.684400e+11   \n",
       "\n",
       "       f83        f84      f85           f86      f87     f88      f89  \\\n",
       "0   69.264  5494800.0  1239.00  5.349300e+08   5.3086  182.59   829.17   \n",
       "1  810.300   860670.0  2165.20  2.711500e+08  10.2320  515.41   262.71   \n",
       "2  212.830  7891000.0   277.16  4.047900e+10   1.1170  393.51  8859.10   \n",
       "\n",
       "      f90       f91      f92     f93      f94       f95     f96      f97  \\\n",
       "0  5.2319  0.010301  3640.80  112.12 -0.43442  11.16100  3755.7  0.99926   \n",
       "1  5.6357  0.374220   420.16  116.23  1.26980   0.78619  1207.0  1.00070   \n",
       "2  8.8098  0.405350   393.65  305.14  1.32660  30.85200  2803.7  0.99925   \n",
       "\n",
       "            f98     f99      f100     f101      f102     f103     f104  \\\n",
       "0  5.338200e+10  1.3867 -0.001878  58.7940   75657.0   187.24  1258.90   \n",
       "1  2.065000e+13  1.2888  0.248850   9.9857   16323.0   244.46   647.58   \n",
       "2  4.722600e+12  1.5003  0.493380  37.0470  139070.0  2464.00  4724.80   \n",
       "\n",
       "      f105      f106      f107         f108     f109     f110    f111  \\\n",
       "0  0.16334  0.055398  0.020002  795640000.0  0.16253 -22.1890  2.0655   \n",
       "1  0.25382  0.008800  0.018479  112060000.0  0.81528  -1.6342  1.5736   \n",
       "2  0.29916  0.093046  0.018516   65193000.0  0.81831 -32.7800  2.1364   \n",
       "\n",
       "      f112     f113     f114    f115          f116    f117     f118  \n",
       "0  0.43088 -10.7410  81606.0  1.1940  1.980400e+14  2017.1  0.46357  \n",
       "1 -1.07120  11.8320  90114.0  1.1507  4.388000e+16  6638.9  0.28125  \n",
       "2 -1.93120  -3.2804  37739.0  1.1548  1.718100e+14  5844.0  0.13797  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T12:59:43.348796Z",
     "iopub.status.busy": "2021-09-07T12:59:43.348482Z",
     "iopub.status.idle": "2021-09-07T12:59:44.374668Z",
     "shell.execute_reply": "2021-09-07T12:59:44.373921Z",
     "shell.execute_reply.started": "2021-09-07T12:59:43.348762Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATASET INFORMATION\n",
      "\n",
      "Length of data: 957919\n",
      "\n",
      "      type  count\n",
      "0  float64    118\n",
      "1    int64      2\n",
      "\n",
      "All features have missing values: True\n",
      "Mean of missing values is 15430 (1.61%)\n",
      "Max of missing values has f31: 15678 (1.64%)\n",
      "Min of missing values has f102: 15168 (1.58%)\n",
      "---------------------------------------------\n",
      "TEST DATASET INFORMATION\n",
      "\n",
      "Length of data: 493474\n",
      "\n",
      "      type  count\n",
      "0  float64    118\n",
      "1    int64      1\n",
      "\n",
      "All features have missing values: True\n",
      "Mean of missing values is 7934 (1.61%)\n",
      "Max of missing values has f64: 8141 (1.65%)\n",
      "Min of missing values has f4: 7733 (1.57%)\n"
     ]
    }
   ],
   "source": [
    "cols = train.drop(['id', 'claim'], axis = 1).columns.tolist()\n",
    "def info(data):\n",
    "    \n",
    "    print(f'Length of data: {len(data)}')\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    x = pd.Series([])\n",
    "    for i in data.columns.tolist():\n",
    "        x = x.append(pd.Series([data[i].dtypes]))\n",
    "    \n",
    "    print(x.value_counts().to_frame().reset_index().rename(columns={0: 'count', 'index': 'type'}))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    flag = True\n",
    "    for i in cols:\n",
    "        if data[i].isna().sum() == 0:\n",
    "            flag = False\n",
    "            break\n",
    "            \n",
    "    print(f'All features have missing values: {flag}')\n",
    "    \n",
    "    list_na = []\n",
    "    for i in cols:\n",
    "        list_na.append(data[i].isna().sum())\n",
    "    print(f'Mean of missing values is {mean(list_na)} ({round((mean(list_na)/len(data)) * 100,2)}%)')\n",
    "    print(f'Max of missing values has {cols[list_na.index(max(list_na))]}: {max(list_na)} ({round((max(list_na)/len(data)) * 100,2)}%)')\n",
    "    print(f'Min of missing values has {cols[list_na.index(min(list_na))]}: {min(list_na)} ({round((min(list_na)/len(data)) * 100,2)}%)')\n",
    "\n",
    "print('TRAINING DATASET INFORMATION')\n",
    "print('')\n",
    "info(train)\n",
    "print('---------------------------------------------')\n",
    "print('TEST DATASET INFORMATION')\n",
    "print('')\n",
    "info(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T12:59:44.377546Z",
     "iopub.status.busy": "2021-09-07T12:59:44.377303Z",
     "iopub.status.idle": "2021-09-07T13:11:51.311198Z",
     "shell.execute_reply": "2021-09-07T13:11:51.310336Z",
     "shell.execute_reply.started": "2021-09-07T12:59:44.377522Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 71))\n",
    "cols = train.columns.tolist()[1:119]\n",
    "for i in cols:\n",
    "    plt.subplot(24,5,cols.index(i)+1)\n",
    "    sns.set_style(\"white\")\n",
    "    plt.title(i, size = 12, fontname = 'monospace')\n",
    "    a = sns.kdeplot(train[i], color = '#f9ba32', linewidth = 1.3)\n",
    "    sns.kdeplot(test[i], color = '#426e86', linewidth = 1.3)\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks(fontname = 'monospace')\n",
    "    plt.yticks([])\n",
    "    for j in ['right', 'left', 'top']:\n",
    "        a.spines[j].set_visible(False)\n",
    "        a.spines['bottom'].set_linewidth(1.2)\n",
    "        \n",
    "fig.tight_layout(h_pad = 3)\n",
    "\n",
    "plt.figtext(0.335, 1.02, 'Distribution of features', color = '#2f3131', fontname = 'monospace', size = 25)\n",
    "plt.figtext(0.3, 1.01, 'train', color = '#f9ba32', fontname = 'monospace', size = 18)\n",
    "plt.figtext(0.66, 1.01, 'test', color = '#426e86', fontname = 'monospace', size = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T13:11:51.312928Z",
     "iopub.status.busy": "2021-09-07T13:11:51.312561Z",
     "iopub.status.idle": "2021-09-07T13:11:53.046263Z",
     "shell.execute_reply": "2021-09-07T13:11:53.044923Z",
     "shell.execute_reply.started": "2021-09-07T13:11:51.312889Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "retarget = {0: 'No claim', 1: 'Claim'}\n",
    "train['claim'] = train['claim'].map(retarget)\n",
    "\n",
    "fig = px.pie(train['claim'].value_counts().reset_index(), values = 'claim', names = 'index', width = 700, height = 700)\n",
    "fig.update_traces(textposition = 'inside', \n",
    "                  textinfo = 'percent + label', \n",
    "                  hole = 0.8, \n",
    "                  marker = dict(colors = ['#f9ba32','#426e86'], line = dict(color = 'white', width = 2)))\n",
    "\n",
    "fig.update_layout(annotations = [dict(text = 'Distribution of the target', \n",
    "                                      x = 0.5, y = 0.5, font_size = 28, showarrow = False, \n",
    "                                      font_family = 'monospace',\n",
    "                                      font_color = '#283655')],\n",
    "                  showlegend = False)\n",
    "                  \n",
    "fig.show()\n",
    "\n",
    "retarget = {'No claim': 0, 'Claim': 1}\n",
    "train['claim'] = train['claim'].map(retarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T13:11:53.049028Z",
     "iopub.status.busy": "2021-09-07T13:11:53.048464Z",
     "iopub.status.idle": "2021-09-07T13:13:00.027034Z",
     "shell.execute_reply": "2021-09-07T13:13:00.026199Z",
     "shell.execute_reply.started": "2021-09-07T13:11:53.048961Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "matrix = np.triu(train.drop('id', axis = 1).corr())\n",
    "plt.figure(figsize = (15, 12))\n",
    "sns.heatmap(train.drop('id', axis = 1).corr(), annot = False, cmap = 'Spectral', mask = matrix, vmin = -0.05, vmax = 0.05, linewidths = 0.1, linecolor = 'white', cbar = True)\n",
    "plt.xticks(size = 8, fontname = 'monospace')\n",
    "plt.yticks(size = 8, fontname = 'monospace')\n",
    "plt.figtext(0.77, 0.8, '''All 118 features and the target variable\n",
    "have a very small\n",
    "correlation''', fontsize = 20, fontname = 'monospace', ha = 'right', color = '#f9ba32')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T13:13:00.029904Z",
     "iopub.status.busy": "2021-09-07T13:13:00.029417Z",
     "iopub.status.idle": "2021-09-07T13:13:32.493222Z",
     "shell.execute_reply": "2021-09-07T13:13:32.492341Z",
     "shell.execute_reply.started": "2021-09-07T13:13:00.029866Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "corr = train.drop('id', axis = 1).corr()['claim'].reset_index().drop(index=[118])\n",
    "min_corr = corr.min()[1]\n",
    "max_corr = corr.max()[1]\n",
    "corr.query(\"claim == @min_corr | claim == @max_corr\").rename(columns = {'index': 'feature'}).rename(index = {33: 'max_neg_correlation', 94: 'max_pos_correlation'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T13:13:32.495514Z",
     "iopub.status.busy": "2021-09-07T13:13:32.495078Z",
     "iopub.status.idle": "2021-09-07T13:14:22.136625Z",
     "shell.execute_reply": "2021-09-07T13:14:22.135653Z",
     "shell.execute_reply.started": "2021-09-07T13:13:32.495474Z"
    }
   },
   "outputs": [],
   "source": [
    "features = train.columns.tolist()[1:119]\n",
    "\n",
    "train['n_missing'] = train[features].isna().sum(axis = 1)\n",
    "test['n_missing'] = test[features].isna().sum(axis = 1)\n",
    "\n",
    "train['std'] = train[features].std(axis = 1)\n",
    "test['std'] = test[features].std(axis = 1)\n",
    "\n",
    "features += ['n_missing', 'std']\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "for i in features:\n",
    "    train[i] = imputer.fit_transform(np.array(train[i]).reshape(-1,1))\n",
    "    test[i] = imputer.transform(np.array(test[i]).reshape(-1,1))\n",
    "\n",
    "sc = StandardScaler()\n",
    "train[features] = sc.fit_transform(train[features])\n",
    "test[features] = sc.transform(test[features])\n",
    "\n",
    "X = train.drop(['id', 'claim'], axis = 1)\n",
    "y = train['claim']\n",
    "test.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory optimization. It would be nice to convert the data to float16, but the XGB for some reason does not support this format. The function is taken from [here](https://www.kaggle.com/rinnqd/reduce-memory-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T13:14:22.138459Z",
     "iopub.status.busy": "2021-09-07T13:14:22.13809Z",
     "iopub.status.idle": "2021-09-07T13:14:22.151459Z",
     "shell.execute_reply": "2021-09-07T13:14:22.149129Z",
     "shell.execute_reply.started": "2021-09-07T13:14:22.138421Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T13:14:22.153343Z",
     "iopub.status.busy": "2021-09-07T13:14:22.15289Z",
     "iopub.status.idle": "2021-09-07T13:14:38.609159Z",
     "shell.execute_reply": "2021-09-07T13:14:38.6084Z",
     "shell.execute_reply.started": "2021-09-07T13:14:22.153307Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T13:14:38.610759Z",
     "iopub.status.busy": "2021-09-07T13:14:38.610412Z",
     "iopub.status.idle": "2021-09-07T13:14:55.288842Z",
     "shell.execute_reply": "2021-09-07T13:14:55.288041Z",
     "shell.execute_reply.started": "2021-09-07T13:14:38.61072Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_mem_usage(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T13:14:55.290369Z",
     "iopub.status.busy": "2021-09-07T13:14:55.290029Z",
     "iopub.status.idle": "2021-09-07T13:15:03.913996Z",
     "shell.execute_reply": "2021-09-07T13:15:03.913222Z",
     "shell.execute_reply.started": "2021-09-07T13:14:55.290331Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-09-07T12:56:06.509609Z",
     "iopub.status.busy": "2021-09-07T12:56:06.509235Z",
     "iopub.status.idle": "2021-09-07T12:56:39.826952Z",
     "shell.execute_reply": "2021-09-07T12:56:39.824331Z",
     "shell.execute_reply.started": "2021-09-07T12:56:06.509563Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, data = X, target = y):\n",
    "\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10000, 50000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 500),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0001, 1.0, log = True),\n",
    "        'alpha': trial.suggest_float('alpha', 0.0001, 10.0, log = True),\n",
    "        'lambda': trial.suggest_float('lambda', 0.0001, 10.0, log = True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'booster': 'gbtree',\n",
    "        'random_state': 228,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    scores = []\n",
    "    k = StratifiedKFold(n_splits = 2, random_state = 228, shuffle = True)\n",
    "    for i, (trn_idx, val_idx) in enumerate(k.split(X, y)):\n",
    "        \n",
    "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 300, verbose = False)\n",
    "        \n",
    "        tr_preds = model.predict_proba(X_train)[:,1]\n",
    "        tr_score = roc_auc_score(y_train, tr_preds)\n",
    "        \n",
    "        val_preds = model.predict_proba(X_val)[:,1]\n",
    "        val_score = roc_auc_score(y_val, val_preds)\n",
    "\n",
    "        scores.append((tr_score, val_score))\n",
    "        \n",
    "        print(f\"Fold {i+1} | AUC: {val_score}\")\n",
    "        \n",
    "        \n",
    "    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n",
    "    \n",
    "    return scores['validation score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 300)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best value:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T13:15:03.915665Z",
     "iopub.status.busy": "2021-09-07T13:15:03.91533Z",
     "iopub.status.idle": "2021-09-07T13:15:03.920906Z",
     "shell.execute_reply": "2021-09-07T13:15:03.919992Z",
     "shell.execute_reply.started": "2021-09-07T13:15:03.915628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mean AUC on 2 folds - 0.81501\n",
    "# esr - 300\n",
    "paramsXGB = {'max_depth': 2, 'learning_rate': 0.021537077920105466, 'n_estimators': 10606, 'min_child_weight': 150, 'gamma': 0.11611920725914951, 'alpha': 0.0021839958087869794, 'lambda': 0.0018567979557499344, 'colsample_bytree': 0.7139742731494992, 'subsample': 0.6258627743440968,\n",
    "             'tree_method': 'gpu_hist',\n",
    "             'booster': 'gbtree',\n",
    "             'random_state': 228,\n",
    "             'use_label_encoder': False,\n",
    "             'eval_metric': 'auc'}\n",
    "# Solo result - 0.81762 on 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T18:16:30.371568Z",
     "iopub.status.busy": "2021-09-06T18:16:30.371213Z",
     "iopub.status.idle": "2021-09-06T18:28:06.20435Z",
     "shell.execute_reply": "2021-09-06T18:28:06.20337Z",
     "shell.execute_reply.started": "2021-09-06T18:16:30.371539Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\n",
    "predictions = np.zeros(len(test))\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = XGBClassifier(**paramsXGB)\n",
    "   \n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n",
    "    \n",
    "    predictions += model.predict_proba(test)[:,1] / folds.n_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T18:28:45.596177Z",
     "iopub.status.busy": "2021-09-06T18:28:45.595836Z",
     "iopub.status.idle": "2021-09-06T18:28:47.136066Z",
     "shell.execute_reply": "2021-09-06T18:28:47.135173Z",
     "shell.execute_reply.started": "2021-09-06T18:28:45.596132Z"
    }
   },
   "outputs": [],
   "source": [
    "ss['claim'] = predictions\n",
    "ss.to_csv('xgb1', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T19:05:54.206058Z",
     "iopub.status.busy": "2021-09-06T19:05:54.205673Z",
     "iopub.status.idle": "2021-09-06T19:50:29.691474Z",
     "shell.execute_reply": "2021-09-06T19:50:29.688275Z",
     "shell.execute_reply.started": "2021-09-06T19:05:54.206027Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, data = X, target = y):\n",
    "    \n",
    "    params = {\n",
    "        'depth': trial.suggest_int('depth', 2, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2),\n",
    "        'iterations': trial.suggest_int('iterations', 10000, 50000),\n",
    "        'max_bin': trial.suggest_int('max_bin', 1, 300),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'leaf_estimation_method': trial.suggest_categorical('leaf_estimation_method', ['Newton', 'Gradient']),\n",
    "        'bootstrap_type': 'Bernoulli',\n",
    "        'random_seed': 228,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    scores = []\n",
    "    k = StratifiedKFold(n_splits = 2, random_state = 228, shuffle = True)\n",
    "    for i, (trn_idx, val_idx) in enumerate(k.split(X, y)):\n",
    "        \n",
    "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 300, verbose = False)\n",
    "        \n",
    "        tr_preds = model.predict_proba(X_train)[:,1]\n",
    "        tr_score = roc_auc_score(y_train, tr_preds)\n",
    "        \n",
    "        val_preds = model.predict_proba(X_val)[:,1]\n",
    "        val_score = roc_auc_score(y_val, val_preds)\n",
    "\n",
    "        scores.append((tr_score, val_score))\n",
    "        \n",
    "        print(f\"Fold {i+1} | AUC: {val_score}\")\n",
    "        \n",
    "        \n",
    "    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n",
    "    \n",
    "    return scores['validation score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 300)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best value:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T13:15:03.923148Z",
     "iopub.status.busy": "2021-09-07T13:15:03.922535Z",
     "iopub.status.idle": "2021-09-07T13:15:03.929699Z",
     "shell.execute_reply": "2021-09-07T13:15:03.928859Z",
     "shell.execute_reply.started": "2021-09-07T13:15:03.92311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mean AUC on 2 folds - 0.81495\n",
    "# esr - 300\n",
    "paramsCB = {'depth': 3, 'learning_rate': 0.014530866870832323, 'iterations': 44204, 'max_bin': 265, 'min_data_in_leaf': 14, 'l2_leaf_reg': 0.004427550682515904, 'subsample': 0.5402586792667279, 'grow_policy': 'SymmetricTree', 'leaf_estimation_method': 'Gradient',\n",
    "            'bootstrap_type': 'Bernoulli',\n",
    "            'random_seed': 228,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'task_type': 'GPU' }\n",
    "# Solo result - 0.81739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T19:51:28.803542Z",
     "iopub.status.busy": "2021-09-06T19:51:28.803209Z",
     "iopub.status.idle": "2021-09-06T20:42:11.547564Z",
     "shell.execute_reply": "2021-09-06T20:42:11.546682Z",
     "shell.execute_reply.started": "2021-09-06T19:51:28.803511Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\n",
    "predictions = np.zeros(len(test))\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = CatBoostClassifier(**paramsCB)\n",
    "   \n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n",
    "    \n",
    "    predictions += model.predict_proba(test)[:,1] / folds.n_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-06T20:43:05.599605Z",
     "iopub.status.busy": "2021-09-06T20:43:05.59929Z",
     "iopub.status.idle": "2021-09-06T20:43:07.14062Z",
     "shell.execute_reply": "2021-09-06T20:43:07.139687Z",
     "shell.execute_reply.started": "2021-09-06T20:43:05.599576Z"
    }
   },
   "outputs": [],
   "source": [
    "ss['claim'] = predictions\n",
    "ss.to_csv('cb1', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T21:18:23.420115Z",
     "iopub.status.busy": "2021-09-06T21:18:23.419738Z",
     "iopub.status.idle": "2021-09-06T22:05:23.323708Z",
     "shell.execute_reply": "2021-09-06T22:05:23.321018Z",
     "shell.execute_reply.started": "2021-09-06T21:18:23.420082Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, data = X, target = y):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000, 15000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 3),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 50, 500),\n",
    "        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 200),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'random_state': 228,\n",
    "        'metric': 'auc',\n",
    "        'device_type': 'gpu',\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**params)\n",
    "    scores = []\n",
    "    k = StratifiedKFold(n_splits = 2, random_state = 228, shuffle = True)\n",
    "    for i, (trn_idx, val_idx) in enumerate(k.split(X, y)):\n",
    "        \n",
    "        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 300, verbose = False)\n",
    "        \n",
    "        tr_preds = model.predict_proba(X_train)[:,1]\n",
    "        tr_score = roc_auc_score(y_train, tr_preds)\n",
    "        \n",
    "        val_preds = model.predict_proba(X_val)[:,1]\n",
    "        val_score = roc_auc_score(y_val, val_preds)\n",
    "\n",
    "        scores.append((tr_score, val_score))\n",
    "        \n",
    "        print(f\"Fold {i+1} | AUC: {val_score}\")\n",
    "        \n",
    "        \n",
    "    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n",
    "    \n",
    "    return scores['validation score'].mean()\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 100)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best value:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T13:15:03.931373Z",
     "iopub.status.busy": "2021-09-07T13:15:03.930966Z",
     "iopub.status.idle": "2021-09-07T13:15:03.942324Z",
     "shell.execute_reply": "2021-09-07T13:15:03.941462Z",
     "shell.execute_reply.started": "2021-09-07T13:15:03.931338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mean AUC on 2 folds - 0.8151\n",
    "paramsLGBM = {'n_estimators': 11990, 'max_depth': 3, 'learning_rate': 0.016501612373246877, 'reg_alpha': 7.555087388180319, 'reg_lambda': 0.9534606245427513, 'num_leaves': 155, 'min_data_per_group': 177, 'min_child_samples': 150, 'colsample_bytree': 0.22781593823447946,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'random_state': 228,\n",
    "            'metric': 'auc',\n",
    "            'device_type': 'gpu',\n",
    "            'gpu_platform_id': 0,\n",
    "            'gpu_device_id': 0}\n",
    "# Solo result - 0.81795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T09:27:44.084933Z",
     "iopub.status.busy": "2021-09-07T09:27:44.084526Z",
     "iopub.status.idle": "2021-09-07T10:53:51.131741Z",
     "shell.execute_reply": "2021-09-07T10:53:51.13059Z",
     "shell.execute_reply.started": "2021-09-07T09:27:44.084902Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\n",
    "predictions = np.zeros(len(test))\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = LGBMClassifier(**paramsLGBM)\n",
    "   \n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n",
    "    \n",
    "    predictions += model.predict_proba(test)[:,1] / folds.n_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T10:54:05.329966Z",
     "iopub.status.busy": "2021-09-07T10:54:05.329596Z",
     "iopub.status.idle": "2021-09-07T10:54:05.337779Z",
     "shell.execute_reply": "2021-09-07T10:54:05.336195Z",
     "shell.execute_reply.started": "2021-09-07T10:54:05.329934Z"
    }
   },
   "outputs": [],
   "source": [
    "ss['claim'] = predictions\n",
    "ss.to_csv('lgbm1', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T13:15:03.944124Z",
     "iopub.status.busy": "2021-09-07T13:15:03.943687Z",
     "iopub.status.idle": "2021-09-07T13:15:03.954517Z",
     "shell.execute_reply": "2021-09-07T13:15:03.953734Z",
     "shell.execute_reply.started": "2021-09-07T13:15:03.94409Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(**paramsXGB)\n",
    "cb_model = CatBoostClassifier(**paramsCB)\n",
    "lgbm_model = LGBMClassifier(**paramsLGBM)\n",
    "\n",
    "# XGB solo result - 0.81762\n",
    "# CB solo result - 0.81739\n",
    "# LGBM solo result - 0.81795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T16:18:02.69283Z",
     "iopub.status.busy": "2021-09-07T16:18:02.692443Z",
     "iopub.status.idle": "2021-09-07T18:46:00.686972Z",
     "shell.execute_reply": "2021-09-07T18:46:00.685865Z",
     "shell.execute_reply.started": "2021-09-07T16:18:02.692775Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\n",
    "\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = VotingClassifier(\n",
    "            estimators = [\n",
    "                ('xgb', xgb_model),\n",
    "                ('cb', cb_model),\n",
    "                ('lgbm', lgbm_model)       \n",
    "            ],\n",
    "            voting = 'soft',\n",
    "            weights = [0.3, 0.2, 0.5],\n",
    "            n_jobs = -1\n",
    "        )\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions += model.predict_proba(test)[:,1] / folds.n_splits\n",
    "    \n",
    "ss['claim'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T18:48:16.704327Z",
     "iopub.status.busy": "2021-09-07T18:48:16.703974Z",
     "iopub.status.idle": "2021-09-07T18:48:18.435856Z",
     "shell.execute_reply": "2021-09-07T18:48:18.434973Z",
     "shell.execute_reply.started": "2021-09-07T18:48:16.704293Z"
    }
   },
   "outputs": [],
   "source": [
    "ss.to_csv('voting!', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T18:48:01.704104Z",
     "iopub.status.busy": "2021-09-07T18:48:01.703782Z",
     "iopub.status.idle": "2021-09-07T18:48:01.715229Z",
     "shell.execute_reply": "2021-09-07T18:48:01.714446Z",
     "shell.execute_reply.started": "2021-09-07T18:48:01.704074Z"
    }
   },
   "outputs": [],
   "source": [
    "ss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
